diff --git a/mast3r_slam/backend/src/gn_kernels.cu b/mast3r_slam/backend/src/gn_kernels.cu
index bf2d588..19f769b 100644
--- a/mast3r_slam/backend/src/gn_kernels.cu
+++ b/mast3r_slam/backend/src/gn_kernels.cu
@@ -799,7 +799,7 @@ std::vector<torch::Tensor> gauss_newton_points_cuda(
 
     // Termination criteria
     // Need to specify this second argument otherwise ambiguous function call...
-    delta_norm = torch::linalg::linalg_norm(dx, std::optional<c10::Scalar>(), {}, false, {});
+    delta_norm = dx.flatten().norm();
     if (delta_norm.item<float>() < delta_thresh) {
       break;
     }
@@ -1216,7 +1216,7 @@ std::vector<torch::Tensor> gauss_newton_rays_cuda(
 
     // Termination criteria
     // Need to specify this second argument otherwise ambiguous function call...
-    delta_norm = torch::linalg::linalg_norm(dx, std::optional<c10::Scalar>(), {}, false, {});
+    delta_norm = dx.flatten().norm();
     if (delta_norm.item<float>() < delta_thresh) {
       break;
     }
@@ -1626,7 +1626,7 @@ std::vector<torch::Tensor> gauss_newton_calib_cuda(
 
     // Termination criteria
     // Need to specify this second argument otherwise ambiguous function call...
-    delta_norm = torch::linalg::linalg_norm(dx, std::optional<c10::Scalar>(), {}, false, {});
+    delta_norm = dx.flatten().norm();
     if (delta_norm.item<float>() < delta_thresh) {
       break;
     }
@@ -1635,4 +1635,4 @@ std::vector<torch::Tensor> gauss_newton_calib_cuda(
   }
 
   return {dx}; // For debugging
-}
\ No newline at end of file
+}
diff --git a/mast3r_slam/backend/src/matching_kernels.cu b/mast3r_slam/backend/src/matching_kernels.cu
index 288fa4c..c4fe931 100644
--- a/mast3r_slam/backend/src/matching_kernels.cu
+++ b/mast3r_slam/backend/src/matching_kernels.cu
@@ -100,7 +100,7 @@ std::vector<torch::Tensor> refine_matches_cuda(
   torch::Tensor p1_new = torch::zeros(
     {batch_size, n, 2}, opts);
 
-  AT_DISPATCH_FLOATING_TYPES_AND_HALF(D11.type(), "refine_matches_kernel", ([&] {
+  AT_DISPATCH_FLOATING_TYPES_AND_HALF(D11.scalar_type(), "refine_matches_kernel", ([&] {
     refine_matches_kernel<scalar_t><<<blocks, threads>>>(
       D11.packed_accessor32<scalar_t,4,torch::RestrictPtrTraits>(),
       D21.packed_accessor32<scalar_t,3,torch::RestrictPtrTraits>(),
@@ -313,4 +313,4 @@ std::vector<torch::Tensor> iter_proj_cuda(
 
   return {p_new, converged};
 
-}
\ No newline at end of file
+}
diff --git a/thirdparty/in3d/setup.py b/thirdparty/in3d/setup.py
index 669bb5a..2addbac 100644
--- a/thirdparty/in3d/setup.py
+++ b/thirdparty/in3d/setup.py
@@ -1,12 +1,9 @@
 from pathlib import Path
 from setuptools import setup
 
-thirdparty_path = Path(__file__).parent / "thirdparty"
-pyimgui_path = (thirdparty_path / "pyimgui").as_uri()
-
 setup(
     install_requires=[
-        f"imgui @ {pyimgui_path}",
+        "imgui>=2.0.0",
         "moderngl==5.12.0",
         "moderngl-window==2.4.6",
         "glfw",
diff --git a/thirdparty/mast3r/dust3r/croco/models/curope/kernels.cu b/thirdparty/mast3r/dust3r/croco/models/curope/kernels.cu
index 7156cd1..bf777c2 100644
--- a/thirdparty/mast3r/dust3r/croco/models/curope/kernels.cu
+++ b/thirdparty/mast3r/dust3r/croco/models/curope/kernels.cu
@@ -98,7 +98,7 @@ void rope_2d_cuda( torch::Tensor tokens, const torch::Tensor pos, const float ba
     const int N_BLOCKS = B * N; // each block takes care of H*D values
     const int SHARED_MEM = sizeof(float) * (D + D/4);
 
-    AT_DISPATCH_FLOATING_TYPES_AND_HALF(tokens.type(), "rope_2d_cuda", ([&] {
+    AT_DISPATCH_FLOATING_TYPES_AND_HALF(tokens.scalar_type(), "rope_2d_cuda", ([&] {
         rope_2d_cuda_kernel<scalar_t> <<<N_BLOCKS, THREADS_PER_BLOCK, SHARED_MEM>>> (
             //tokens.data_ptr<scalar_t>(), 
             tokens.packed_accessor32<scalar_t,4,torch::RestrictPtrTraits>(),
diff --git a/thirdparty/mast3r/mast3r/model.py b/thirdparty/mast3r/mast3r/model.py
index f328c5e..ab95301 100644
--- a/thirdparty/mast3r/mast3r/model.py
+++ b/thirdparty/mast3r/mast3r/model.py
@@ -21,7 +21,7 @@ inf = float('inf')
 def load_model(model_path, device, verbose=True):
     if verbose:
         print('... loading model from', model_path)
-    ckpt = torch.load(model_path, map_location='cpu')
+    ckpt = torch.load(model_path, map_location='cpu', weights_only=False)
     args = ckpt['args'].model.replace("ManyAR_PatchEmbed", "PatchEmbedDust3R")
     if 'landscape_only' not in args:
         args = args[:-1] + ', landscape_only=False)'
diff --git a/thirdparty/mast3r/mast3r/retrieval/processor.py b/thirdparty/mast3r/mast3r/retrieval/processor.py
index 735bdc0..fa4d02e 100644
--- a/thirdparty/mast3r/mast3r/retrieval/processor.py
+++ b/thirdparty/mast3r/mast3r/retrieval/processor.py
@@ -67,7 +67,7 @@ class Retriever(object):
         # load the model
         assert os.path.isfile(modelname), modelname
         print(f'Loading retrieval model from {modelname}')
-        ckpt = torch.load(modelname, 'cpu')  # TODO from pretrained to download it automatically
+        ckpt = torch.load(modelname, map_location='cpu', weights_only=False)  # TODO from pretrained to download it automatically
         ckpt_args = ckpt['args']
         if backbone is None:
             backbone = AsymmetricMASt3R.from_pretrained(ckpt_args.pretrained)
@@ -126,4 +126,4 @@ class Retriever(object):
                 os.makedirs(os.path.dirname(outfile), exist_ok=True)
             np.save(outfile, scores)
             print(f'Scores matrix saved in {outfile}')
-        return scores
\ No newline at end of file
+        return scores
diff --git a/changes_fixed.md b/changes_fixed.md
new file mode 100644
index 0000000..a775d88
--- /dev/null
+++ b/changes_fixed.md
@@ -0,0 +1,7 @@
+## Changes Applied
+
+- Updated `thirdparty/mast3r/dust3r/croco/models/curope/kernels.cu` to use `tokens.scalar_type()` when dispatching CUDA kernels so the build works with recent PyTorch versions.
+- Switched `mast3r_slam/backend/src/matching_kernels.cu` to call `AT_DISPATCH_FLOATING_TYPES_AND_HALF` with `D11.scalar_type()` to avoid deprecated type errors during compilation.
+- Replaced the PyTorch linear algebra norm call in `mast3r_slam/backend/src/gn_kernels.cu` with `dx.flatten().norm()` at the three convergence checks for better compatibility.
+- Pointed `thirdparty/in3d/setup.py` at the PyPI `imgui` package instead of the incomplete bundled submodule so the dependency installs cleanly.
+- Set `weights_only=False` when loading MASt3R checkpoints (`thirdparty/mast3r/mast3r/model.py`) and retrieval weights (`thirdparty/mast3r/mast3r/retrieval/processor.py`) so PyTorch 2.6+ can deserialize them.
